# Determine the total number of records in the table.
nrow(elect_nas_df)
round(nrow(elect_nas_df)/nrow(elect_data_df)*100,3)
# Determine the total number of votes cast across all counties in all elections.
elect_vt_cnt_df <- elect_data_df %>%
summarise(count= sum(candidatevotes))
elect_vt_cnt_df
# Determine how many votes are associated with state-level counts
elect_null_fips_cnt_df <- elect_nas_df %>%
summarise(count=sum(candidatevotes))
elect_null_fips_cnt_df
round((elect_null_fips_cnt_df$count/elect_vt_cnt_df$count)*100,3)
#transform data- drop NAs, keep dem and gop only, group records for each candidate by county and year
elect_cand_vt_df <- elect_data_df %>%
filter(!is.na(FIPS), pol_identity %in% c('DEMOCRAT', 'REPUBLICAN')) %>%
group_by(FIPS,county_name, state, candidate, year, pol_identity, totalvotes) %>%
summarise(candidate_votes = sum(candidatevotes)) %>%
ungroup() %>%
arrange(FIPS, year)
#spread the candidate votes values
elect_pivot_df <- elect_cand_vt_df %>%
pivot_wider(id_cols = c(year, FIPS, county_name, state, totalvotes),
names_from = pol_identity,
values_from = candidate_votes) %>%
rename(votes_dem = DEMOCRAT,  votes_gop = REPUBLICAN
#votes_other = OTHER,votes_grn = GREEN, votes_lib = LIBERTARIAN
)
#CVAP- Citizen Voting Age Population, Census Bureau population estimates generated using the American Community Survey
#https://www.census.gov/programs-surveys/decennial-census/about/voting-rights/cvap.2010.html#list-tab-1518558936 (2008)
cens_cvap2008_df <- read_csv("https://raw.githubusercontent.com/GitableGabe/DATA_698/refs/heads/main/data/CountyCVAP_2006-2010.csv?token=GHSAT0AAAAAACXYKDAYQCHUVJY2V6BVWU7SZXPAZJQ") %>%
rename_with(tolower) %>%
mutate(year=2008)
#https://www.census.gov/programs-surveys/decennial-census/about/voting-rights/cvap.2014.html#list-tab-1518558936 (2012)
cens_cvap2012_df <- read_csv("https://raw.githubusercontent.com/GitableGabe/DATA_698/refs/heads/main/data/CountyCVAP_2010-2014.csv?token=GHSAT0AAAAAACXYKDAYHOL27SGWSEL2AS6IZXPAYSQ") %>%
rename_with(tolower) %>%
mutate(year=2012)
#https://www.census.gov/programs-surveys/decennial-census/about/voting-rights/cvap/2014-2018-CVAP.html (2016)
cens_cvap2016_df <- read_csv("https://raw.githubusercontent.com/GitableGabe/DATA_698/refs/heads/main/data/CountyCVAP_2014-2018.csv?token=GHSAT0AAAAAACXYKDAZJU7ABMJMRNP5WOSIZXPATUQ") %>%
mutate(year=2016)
#https://www.census.gov/programs-surveys/decennial-census/about/voting-rights/cvap/2017-2021-CVAP.html (2020)
cens_cvap2020_df <- read_csv("https://raw.githubusercontent.com/GitableGabe/DATA_698/refs/heads/main/data/CountyCVAP_2017-2021.csv?token=GHSAT0AAAAAACXYKDAYJWVR6SZPSH4NRMSSZXPASSQ") %>%
mutate(year=2020)
cens_cvap_df <- rbind(cens_cvap2008_df, cens_cvap2012_df, cens_cvap2016_df, cens_cvap2020_df) %>%
filter(lntitle == 'Total', !str_detect(geoname, "Puerto Rico")) %>%
mutate(FIPS = str_sub(geoid, -5)) %>%
select(c('year', 'FIPS', 'geoname', 'cvap_est'))
#identify empty and NA values
colSums(cens_cvap_df == "" | is.na(cens_cvap_df))
vot_info_df <- left_join(elect_pivot_df, cens_cvap_df, by = c("FIPS", "year"))
vot_info_df
#identify empty and NA values
colSums(vot_info_df == "" | is.na(vot_info_df))
vot_info_NAs_df <- vot_info_df %>%
filter(is.na(geoname), is.na(cvap_est))
vot_info_NAs_df
unique(vot_info_NAs_df$year)
vot_info_df <- vot_info_df %>%
filter(year >= 2008)
vot_info_NAs_2df <- vot_info_df %>%
filter(is.na(geoname), is.na(cvap_est))
vot_info_NAs_2df
vot_info_df <- vot_info_df %>%
filter(state != "ALASKA")
vot_info_NAs_3df <- vot_info_df %>%
filter(is.na(geoname), is.na(cvap_est))
vot_info_NAs_3df
vot_info_clean_df <- vot_info_df %>%
filter(FIPS %in% c('29095', '36000', '51019', '51515')) %>%
arrange(year, FIPS)
vot_info_clean_df
vot_info_clean_df %>%
count(FIPS, state, county_name, geoname) %>%
filter(geoname %in% c("Jackson County, Missouri", "Bedford County, Virginia")) %>%
select(-n)
# Define the counties to filter and group data by year and state
vot_co_grps_df <- vot_info_df %>%
filter(FIPS %in% c('29095', '36000', '51019', '51515')) %>%
group_by(year, state) %>%
summarise(    # Concatenate FIPS codes and county names
FIPS = paste(unique(FIPS), collapse = ", "),
county_name = paste(unique(county_name), collapse = ", "),
across(where(is.numeric), sum, na.rm = TRUE)) %>%
mutate(geoname = case_when(state == "MISSOURI" ~ "Jackson County, Missouri",
state == "VIRGINIA" ~ "Bedford County, Virginia"))
vot_co_grps_df
#remove the previous observations
vot_info_df <- vot_info_df %>%
filter(!FIPS %in% c('29095', '36000', '51019', '51515'))
#replace with the calculated observations
vot_info_df <- rbind(vot_info_df, vot_co_grps_df)
ls_FIPS <- unique(vot_info_df$FIPS)
length(ls_FIPS)
co_names <- vot_info_df %>%
group_by(state, county_name) %>%
mutate(county_name = str_to_title(county_name),
state = str_to_title(state)) %>%
summarise(n=n())
length(co_names)
vot_info_df %>%
group_by(year) %>%
summarise(total_dem = sum(votes_dem),
total_gop = sum(votes_gop)) %>%
mutate(result = if_else(total_gop > total_dem, "Republican Party","Democratic Party"))
rm(list = ls(pattern = "^elect_|^cens_"))
vot_info_df <- vot_info_df %>%
group_by(state, year) %>%
summarise(totalvotes = sum(totalvotes),
votes_dem = sum(votes_dem),
votes_gop = sum(votes_gop),
cvap_est = sum(cvap_est)) %>%
ungroup() %>%
arrange(state, year)
#49 states + DC, Alaska has been removed
length(unique(vot_info_df$state))
vot_info_fin <- vot_info_df %>%
mutate(#voters who did not choose the Democratic or Republican party
votes_other = totalvotes - votes_dem - votes_gop,
#voter share attributes
voter_share_major_party = (votes_dem + votes_gop) / totalvotes,
voter_share_dem = votes_dem/totalvotes,
voter_share_gop = votes_gop/totalvotes,
voter_share_other = votes_other/totalvotes,
#raw differences
rawdiff_dem_vs_gop = votes_dem - votes_gop,
rawdiff_gop_vs_dem = votes_gop - votes_dem,
rawdiff_dem_vs_other = votes_dem - votes_other,
rawdiff_gop_vs_other = votes_gop - votes_other,
rawdiff_other_vs_dem = votes_other - votes_dem,
rawdiff_other_vs_gop = votes_other - votes_gop,
#percentage difference
pctdiff_dem_vs_gop = (votes_dem - votes_gop) / totalvotes,
pctdiff_gop_vs_dem = (votes_gop - votes_dem) / totalvotes,
pctdiff_dem_vs_other = (votes_dem - votes_other) / totalvotes,
pctdiff_gop_vs_other = (votes_gop - votes_other) / totalvotes,
pctdiff_other_vs_dem = (votes_other - votes_dem) / totalvotes,
pctdiff_other_vs_gop = (votes_other - votes_gop) / totalvotes,
#voter turnout
voter_turnout = totalvotes/cvap_est,
voter_turnout_majparty = (votes_dem+votes_gop)/cvap_est,
voter_turnout_dem = votes_dem/cvap_est,
voter_turnout_gop = votes_gop/cvap_est,
voter_turnout_other =votes_other/cvap_est,
# get winning political party
winning_party = case_when(votes_dem > votes_gop & votes_dem > votes_other ~ "Democratic Party",
votes_gop > votes_dem & votes_gop > votes_other ~ "Republican Party",
votes_other > votes_dem & votes_other > votes_gop ~ "Other Party"),
pct_margin_of_victory = case_when(winning_party == "Democratic Party" ~ round(((votes_dem - votes_gop) / totalvotes)*100,3), #votes_dem > votes_gop
winning_party == "Republican Party" ~ round(((votes_gop - votes_dem) / totalvotes)*100,3), #votes_gop > votes_dem
),
# create binary outcome version of the variable for model use
winning_party_binary = case_when(votes_dem > votes_gop & votes_dem > votes_other ~ 0,
votes_gop > votes_dem & votes_gop > votes_other ~ 1,
votes_other > votes_dem & votes_other > votes_gop ~ 2),
)
rm(list = ls()[!grepl("vot_info_fin|^ls_", ls())])
vot_info_fin %>%
group_by(year, winning_party) %>%
summarise(count= n()) %>%
pivot_wider(id_cols = year,
names_from = winning_party,
values_from = count) %>%
mutate(result = case_when(`Republican Party` > `Democratic Party` ~ "Republican Party",
`Democratic Party` > `Republican Party` ~ "Democratic Party",
`Democratic Party` == `Republican Party` ~ "Tie"
)
)
summary(vot_info_fin$voter_turnout)
vot_info_fin <- vot_info_fin %>%
mutate(voter_turnout = if_else(voter_turnout>1 , 1, voter_turnout))
summary(vot_info_fin$voter_turnout)
dim(vot_info_fin)
vot_info_fin_pivot <- vot_info_fin %>%
pivot_wider(
id_cols = c(state),
names_from = year,
values_from = c(totalvotes, cvap_est, voter_turnout, voter_turnout_dem, voter_turnout_gop, pctdiff_dem_vs_gop, rawdiff_dem_vs_gop,
winning_party,winning_party_binary)
)
dim(vot_info_fin_pivot)
colSums(is.na(vot_info_fin_pivot))
vot_info_fin_pivot_na <- vot_info_fin_pivot %>%
filter(if_any(where(is.numeric), is.na))
vot_info_fin_pivot_na
glimpse(vot_info_fin_pivot)
#identify empty and NA values
colSums(vot_info_fin_pivot == "" | is.na(vot_info_fin_pivot))
vot_info_fin_pivot %>%
group_by(state) %>%
summarise(count = n()) %>%
arrange(desc(count))
vot_info_fin_pivot %>%
# keep(is.numeric) %>%
Hmisc::describe()
# Histograms
vot_info_fin_pivot %>%
keep(is.numeric) %>%
gather() %>%
ggplot(aes(value)) +
facet_wrap(~ key, scales = "free") +
geom_density(fill = "#222222", alpha = 0.5, color = "darkgray") +
geom_histogram(aes(y=..density..), alpha=0.5, fill = "#222222", color="darkgray", position="identity") +
theme(axis.title = element_blank())
vot_info_fin %>%
group_by(year, winning_party) %>%
summarise(count = sum(totalvotes)) %>%
ggplot(aes(x = winning_party, y = count, fill = winning_party)) +  # Map fill to winning_party
scale_fill_manual(values = c("darkblue","red2"))+
geom_col(width = 0.5) +  #adjust the width as needed
facet_wrap(~year) +
theme_bw() + # Setting background as blank
theme(legend.position = "bottom",#legend.position = c(0.11, 0.1), #puts legend inside the plot
# legend.text = element_text(size = 6), #, family = "Arial"
legend.key.size = unit(8, "mm"), #changes the size of the legend symbol
legend.title = element_blank(), #removes legend title
legend.spacing.x = unit(.25, 'cm'),
axis.title = element_blank()
)
cor_df <- vot_info_fin_pivot %>%
select(-c(state, starts_with("winning"))) %>%
keep(is.numeric)
cor_matrix <- cor(cor_df)
# Create a heatmap for the correlation matrix
# Visualize correlation between variables
corrplot.mixed(cor(cor_df %>% keep(is.numeric)), tl.col = 'black', tl.pos = 'lt', upper = "number", lower="shade", shade.col=NA, tl.srt=90 )
vif_data <- vif(lm(totalvotes_2020 ~ ., data=cor_df))  # Fit a linear model and calculate VIF
print(vif_data)
# Convert VIF values to a dataframe for visualization
vif_df <- as.data.frame(vif_data)
vif_df$variables <- rownames(vif_df)
#train
df_subset <- vot_info_fin_pivot %>%
select(-c("winning_party_2008", "winning_party_2012", "winning_party_2020", "winning_party_2016")) %>%
mutate(across(starts_with("winning"), as.factor),
state = as.factor(state))
# Split the data into training and testing sets (70% train, 30% test)
set.seed(123)  # for reproducibility
train_indices <- sample(seq_len(nrow(df_subset)), size = 0.7 * nrow(df_subset))
train_data <- df_subset[train_indices, ]
test_data <- df_subset[-train_indices, ]
rf_model <- randomForest(winning_party_binary_2020 ~ ., data = train_data, ntree = 500, mtry = 5, importance = TRUE)
# View the model summary
print(rf_model)
#evaluate
# Predictions on the test data
predictions <- predict(rf_model, test_data)
table(predictions)
# Confusion matrix to evaluate accuracy
conf_matrix <- confusionMatrix(predictions, test_data$winning_party_binary_2020)
print(conf_matrix)
rm(list = ls(pattern = "^cor|df_subset"))
rf_cv <- train(winning_party_binary_2020 ~ ., data = train_data, method = "rf", trControl = trainControl(method = "cv", number = 10))
print(rf_cv)
# To obtain data for the 2008 population from the American Community Survey (ACS),
# you should use the 2006-2008 ACS 3-Year Estimates. This dataset aggregates data
# collected over those three years, providing insights for the population during that period.
# 5 year ACS data unavailable for 2008. 3 year ACS data was discontinued after 2009.
#load 2008 data using API
ed_attain2008 <- get_acs(
geography = "county",
variables = c(paste0("B15001_00", seq(01,09),"E"),paste0("B15001_0", seq(10,83),"E")),
year = 2008,
survey = "acs3",
cache_table = TRUE) %>%
mutate(year=2008)
#2012 data and onward uses the 5 year ACS data
#load 2012 data using API
ed_attain2012 <- get_acs(
geography = "county",
variables = c(paste0("B15001_00", seq(01,09),"E"),paste0("B15001_0", seq(10,83),"E")),
year = 2012,
survey = "acs5",
cache_table = TRUE) %>%
mutate(year=2012)
#load 2016 data using API
ed_attain2016 <- get_acs(
geography = "county",
variables = c(paste0("B15001_00", seq(01,09),"E"),paste0("B15001_0", seq(10,83),"E")),
year = 2016,
survey = "acs5",
cache_table = TRUE) %>%
mutate(year=2016)
#load 2020 data using API
ed_attain2020 <- get_acs(
geography = "county",
variables = c(paste0("B15001_00", seq(01,09),"E"),paste0("B15001_0", seq(10,83),"E")),
year = 2020,
survey = "acs5",
cache_table = TRUE) %>%
mutate(year=2020)
#check column names
#get column names 2008
url08 <- "https://api.census.gov/data/2008/acs/acs3/groups/B15001.html"
webpage08 <- read_html(url08)
table08 <- webpage08 %>%
html_node("table") %>%  # Adjust the selector if necessary
html_table() %>%
select(c("Name","Label","Concept","Required","Attributes","Limit","Predicate Type","Group"))
filteredtable08 <- table08 %>%
# filter(!is.na(Name) & Name != "") %>%  # Remove rows with NA or empty names
filter(Name %in% c(paste0("B15001_00", seq(01,09),"E"),paste0("B15001_0", seq(10,83),"E")))
# %>%
#    mutate(Label = str_replace_all(Label,", GED, or alternative", ' (includes equivalency)'))
#get column names  2012
url12 <- "https://api.census.gov/data/2012/acs/acs5/groups/B15001.html"
webpage12 <- read_html(url12)
table12 <- webpage12 %>%
html_node("table") %>%  # Adjust the selector if necessary
html_table() %>%
select(c("Name","Label","Concept","Required","Attributes","Limit","Predicate Type","Group"))
filteredtable12 <- table12 %>%
# filter(!is.na(Name) & Name != "") %>%  # Remove rows with NA or empty names
filter(Name %in% c(paste0("B15001_00", seq(01,09),"E"),paste0("B15001_0", seq(10,83),"E")))
# %>%
#    mutate(Label = str_replace_all(Label,", GED, or alternative", ' (includes equivalency)'))
#get column names 2016
url16 <- "https://api.census.gov/data/2016/acs/acs5/groups/B15001.html"
webpage16 <- read_html(url16)
table16 <- webpage16 %>%
html_node("table") %>%  # Adjust the selector if necessary
html_table() %>%
select(c("Name","Label","Concept","Required","Attributes","Limit","Predicate Type","Group"))
filteredtable16 <- table16 %>%
# filter(!is.na(Name) & Name != "") %>%  # Remove rows with NA or empty names
filter(Name %in% c(paste0("B15001_00", seq(01,09),"E"),paste0("B15001_0", seq(10,83),"E")))
#get columnn names 2020
url20 <- "https://api.census.gov/data/2020/acs/acs5/groups/B15001.html"
webpage20 <- read_html(url20)
table20 <- webpage20 %>%
html_node("table") %>%  # Adjust the selector if necessary
html_table() %>%
select(c("Name","Label","Concept","Required","Attributes","Limit","Predicate Type","Group"))
filteredtable20 <- table20 %>%
# filter(!is.na(Name) & Name != "") %>%  # Remove rows with NA or empty names
filter(Name %in% c(paste0("B15001_00", seq(01,09),"E"),paste0("B15001_0", seq(10,83),"E"))) %>%
mutate(Label = str_replace_all(Label,":",""))
#Are column names the same across all ACS data?
table(filteredtable08==filteredtable12)
table(filteredtable08==filteredtable16)
table(filteredtable08==filteredtable20)
table(filteredtable12==filteredtable16)
table(filteredtable12==filteredtable20)
table(filteredtable16==filteredtable20)
#update the mismatches
filteredtable08 <- filteredtable08 %>%
mutate(Label = str_replace_all(Label,", GED, or alternative", ' (includes equivalency)'))
filteredtable12 <- filteredtable12 %>%
mutate(Label = str_replace_all(Label,", GED, or alternative", ' (includes equivalency)'))
#recheck
#Are column names the same across all ACS data?
table(filteredtable08==filteredtable12)
table(filteredtable08==filteredtable16)
table(filteredtable08==filteredtable20)
table(filteredtable12==filteredtable16)
table(filteredtable12==filteredtable20)
table(filteredtable16==filteredtable20)
#yes, they are now so we can just use the column names from the latest ACS
ed_attain <- rbind(ed_attain2008, ed_attain2012, ed_attain2016, ed_attain2020)
ed_colnames <- filteredtable20 %>%
mutate(Name = str_replace_all(Name,"E","")) %>%
select(c(Name, Label))
table(sort(unique(ed_colnames$Name))==sort(unique(ed_attain$variable)))
ed_attain2a <- left_join(ed_attain, ed_colnames, by = c("variable"="Name"))
glimpse(ed_attain2a)
#identify empty and NA values
colSums(ed_attain2a == "" | is.na(ed_attain2a))
# voteFIPS <- unique(voting_info_final_pivot$FIPS)
demoFIPS <- unique(ed_attain2a$GEOID)
ed_attain2 <- ed_attain2a %>%
filter(!GEOID %in% setdiff(demoFIPS, ls_FIPS)) %>% #keep only the fips we have in the voting dataset
separate(col="NAME", into=c("county", "state"), sep=",") %>%
mutate(county = str_remove(county, " County"),
county = if_else(county == "Do√±a Ana", "Dona Ana", county)
)
ed_attain3 <- ed_attain2 %>%
group_by(state, year, variable, Label) %>%
summarise(estimate = sum(estimate),
moe = sum(moe)) %>%
mutate(Label2 = Label) %>%
separate(Label2, into = c("type","value","gender", "age_group", "education"), sep = "!!")
length(unique(ed_attain3$GEOID))
# edcountystate <- ed_attain3 %>%
#   select(GEOID,county, state) %>%
#   distinct(GEOID,county,state) %>%
#   group_by(GEOID) %>%
#   summarise(count=n())
head(ed_attain3, 10)
#identify empty and NA values
colSums(ed_attain3 == "" | is.na(ed_attain3))
ed_attain3_na <- ed_attain3 %>%
filter(is.na(gender) | is.na(age_group) | is.na(education)) #is.na(gender) |
ed_attain3_na %>%
count(variable, Label)
unique(ed_attain3_na$variable)
#total county population
tot_pop <- ed_attain3 %>%
filter(is.na(gender)) %>%
select(state,  estimate, year, value) #value is the column name that will be used to spread/pivot_wider
#male/female county population
gen <- ed_attain3 %>%
filter(is.na(age_group), !is.na(gender)) %>%
select(state,  estimate, year, gender)
#gender and age grp population
age_gen_pop <- ed_attain3_na %>%
filter(!is.na(age_group)) %>%
select(state,  estimate, year, gender, age_group)
#gender, age, education
ed_pop <- ed_attain3 %>%
filter(!is.na(education)) %>%
select(state, estimate, year, gender, age_group, education)
#age, education
age <- ed_pop %>%
group_by(state,  year, age_group) %>%
summarise(estimate = sum(estimate))
#gender, education
ed_pop2 <- ed_pop %>%
group_by(state,  year, gender, education) %>%
summarise(estimate = sum(estimate))
#age, education
ed_pop3 <- ed_pop %>%
group_by(state,  year, age_group,  education) %>%
summarise(estimate = sum(estimate))
#education
ed_pop4 <- ed_pop %>%
group_by(state,  year, education) %>%
summarise(estimate = sum(estimate))
#need to spread/pivot_wider and then merge with main dataset for modelling
#age
age <- ed_pop %>%
group_by(state,  year, age_group) %>%
summarise(estimate = sum(estimate))
#gender
gen <- ed_attain3 %>%
filter(is.na(age_group), !is.na(gender)) %>%
select(state,  estimate, year, gender)
#education level
edu <- ed_pop %>%
group_by(state,  year, education) %>%
summarise(estimate = sum(estimate))
#age pivoted
age2 <- age %>%
pivot_wider(id_cols = c(state),
names_from = c(year,age_group),
values_from = estimate)
colSums(age2 == "" | is.na(age2))
#gender pivoted
gen2 <- gen %>%
pivot_wider(id_cols = c(state),
names_from = c(year, gender),
values_from = estimate)
colSums(gen2 == "" | is.na(gen2))
#edu pivoted
edu2 <- edu %>%
pivot_wider(id_cols = c(state),
names_from = c(year, education),
values_from = estimate)
colSums(edu2 == "" | is.na(edu2))
age2 <- age2 %>%
select(-starts_with("2008"))
gen2 <- gen2 %>%
select(-starts_with("2008"))
edu2 <- edu2 %>%
select(-starts_with("2008"))
dem0 <- left_join(age2, gen2, by = c("state"))
dem <- left_join(dem0, edu2, by = c("state")) %>%
ungroup()
#check dimensions, there is an extra state now
dim(dem)
#na / empty cell check
colSums(dem == "" | is.na(dem))
#check for dupe, no dupe, but Puerto Rico needs to be filtered out
unique(dem$state)
dem <- dem %>%
filter(!str_detect(state, "Puerto Rico")) %>%
mutate(state = trimws(state, which="both"))
vot_info_fin_pivot <- vot_info_fin_pivot %>%
mutate(state = str_to_title(state))
model_data <- left_join(vot_info_fin_pivot, dem, join_by(state == state))
dim(model_data)
colSums(model_data == "" | is.na(model_data))
model_data2 <- model_data %>%
drop_na() %>%
janitor::clean_names()
dim(model_data2)
#train
df_subset2 <- model_data2 %>%
select(-c("winning_party_2008", "winning_party_2012", "winning_party_2020", "winning_party_2016")) %>%
mutate(across(starts_with("winning"), as.factor),
state = as.factor(state))
# Split the data into training and testing sets (70% train, 30% test)
set.seed(123)  # for reproducibility
train_indices2 <- sample(seq_len(nrow(df_subset2)), size = 0.7 * nrow(df_subset2))
train_data2 <- df_subset2[train_indices2, ]
test_data2 <- df_subset2[-train_indices2, ]
rf_model2 <- randomForest(winning_party_binary_2020 ~ ., data = train_data2, ntree = 500, mtry = 5, importance = TRUE)
# View the model summary
print(rf_model2)
#evaluate
# Predictions on the test data
predictions2 <- predict(rf_model2, test_data2)
#0= dem, 1=rep
table(predictions2)
# Confusion matrix to evaluate accuracy
conf_matrix2 <- confusionMatrix(predictions2, test_data2$winning_party_binary_2020)
print(conf_matrix2)
rf_cv2 <- train(winning_party_binary_2020 ~ ., data = train_data2, method = "rf", trControl = trainControl(method = "cv", number = 10))
print(rf_cv2)
predictions_2024 <- predict(rf_model2, df_subset2)
# predictions_2024$predicted_class <-  predictions_2024
#demo = 0, rep = 1
table(predictions_2024) # Republican Party
table(df_subset2$winning_party_binary_2020) #Democratic Party
table(df_subset2$winning_party_binary_2016) #Republican Party
